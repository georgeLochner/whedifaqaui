# Feature Planning Prompt

You are a technical lead planning the implementation of a project phase. Your job is to decompose the phase into features and set up the structure for subsequent task planning.

## Inputs

You will be given:
- **Phase identifier** (e.g., "phase1")
- **Implementation plan location** (e.g., `docs/implementation/phase1.md`)
- **Test specification location** (e.g., `docs/testing/phase1-test-specification.md`)
- **Design docs folder** (e.g., `docs/design/`)

## Your Task

1. Read and understand the implementation plan and test specification
2. Identify natural feature boundaries (self-contained units of work)
3. Create beads features with comprehensive descriptions
4. Create a "Plan tasks" child task for each feature
5. Set up dependencies so features execute sequentially

## Step 1: Read Documentation

Read the following files to understand the phase scope:
- The implementation plan (primary source of what to build)
- The test specification (defines acceptance criteria)
- Relevant design docs (technical details)

## Step 2: Identify Feature Boundaries

A **feature** should be:
- **Self-contained**: Can be developed and tested independently
- **Vertical slice**: Ideally covers one functional area end-to-end
- **Appropriately sized**: 3-8 tasks when decomposed (roughly 1-3 days of work)

Common feature patterns:
- Infrastructure/scaffolding (DB models, config, Docker setup)
- A user story or group of related stories
- A backend API + its frontend consumer
- A processing pipeline stage
- A complete UI flow

Avoid:
- Horizontal slices ("all models", "all APIs") - these create integration pain
- Features so large they'll have 15+ tasks
- Features so small they're really just tasks

## Step 3: Write Feature Descriptions

Each feature description must be **comprehensive enough that an agent can start working with only this description**. Include:

```markdown
# Feature: [Title]

## Overview
[2-3 sentences explaining what this feature delivers and why it matters]

## User Stories Covered
[List story IDs from the implementation plan, e.g., V1, V2, S1]

## Technical Context

### Files to Create
- `path/to/file.py` - [purpose]
- `path/to/component.tsx` - [purpose]

### Files to Modify
- `path/to/existing.py` - [what changes]

### Dependencies
- [External packages needed]
- [Other features that must exist first]

### Key Design Decisions
- [Decision 1 and rationale]
- [Decision 2 and rationale]

## Implementation Notes
[Specific technical guidance - patterns to follow, APIs to use, gotchas to avoid]

## Testing Requirements

### Test Specification Reference
- Document: `docs/testing/phase{N}-test-specification.md`
- Sections: [Which sections cover this feature's user stories]

### Unit Tests
[List test IDs from spec, e.g., V1-U01, V1-U02, V1-F01]

### Integration Tests
[List test IDs, e.g., V1-I01, V1-I02]

### E2E Scenarios
[List E2E scenarios this feature contributes to, e.g., E2E-01, E2E-02]
[Note which scenarios become runnable after this feature completes]

### Quality Gate
This feature is NOT complete until:
- All unit tests for covered stories are passing
- All integration tests for covered stories are passing
- Any E2E scenarios that become runnable with this feature must pass

## Reference Documentation
- `docs/design/relevant-doc.md` - [what it covers]
- `docs/testing/phase{N}-test-specification.md` - [relevant sections]
```

## Step 4: Create Features and Plan Tasks

For each feature, run:

```bash
# Create the feature
bd create --title="[Feature Title]" --type=feature --priority=2 --description="[Full description from Step 3]"

# Note the feature ID returned (e.g., beads-abc123)

# Create the "Plan tasks" task as a child
bd create --title="Plan tasks for [Feature Title]" --type=task --priority=2 --parent=beads-abc123 --description="Read prompt/plan_tasks.txt for instructions. Then create implementation tasks for this feature.

Feature ID: beads-abc123

## Context
[Brief summary of what this feature does - 2-3 sentences]

## Sizing Guidance
Tasks should:
- Modify 1-3 files
- Read no more than 5-8 files for context
- Have ONE clear deliverable
- Be completable within ~50k tokens of context

## Reference
See the feature description (bd show beads-abc123) for full technical context."
```

## Step 5: Set Up Dependencies

Features should be ordered so foundational work comes first. Common patterns:

1. Infrastructure → Backend Core → Backend Features → Frontend
2. Data models → Services → APIs → UI
3. Upload → Processing → Search → Display

For each feature after the first, make its "Plan tasks" task blocked by the previous feature:

```bash
# If Feature B depends on Feature A:
bd dep add beads-plan-tasks-B beads-feature-A
```

This ensures:
- Feature A's tasks complete
- Feature A is closed
- Then "Plan tasks for B" becomes ready
- Feature B's tasks are planned
- Feature B's tasks execute

## Example Output

For a phase with 3 features:

```bash
# Create features
bd create --title="Database Models and Migrations" --type=feature --priority=2 --description="..."
# Returns: beads-feat-001

bd create --title="Video Upload API" --type=feature --priority=2 --description="..."
# Returns: beads-feat-002

bd create --title="Upload UI" --type=feature --priority=2 --description="..."
# Returns: beads-feat-003

# Create plan tasks for each
bd create --title="Plan tasks for Database Models" --type=task --parent=beads-feat-001 --description="..."
# Returns: beads-task-001

bd create --title="Plan tasks for Video Upload API" --type=task --parent=beads-feat-002 --description="..."
# Returns: beads-task-002

bd create --title="Plan tasks for Upload UI" --type=task --parent=beads-feat-003 --description="..."
# Returns: beads-task-003

# Set up dependencies
bd dep add beads-task-002 beads-feat-001  # Plan API waits for Models feature
bd dep add beads-task-003 beads-feat-002  # Plan UI waits for API feature
```

## Checklist Before Closing

- [ ] All features created with comprehensive descriptions
- [ ] Each feature has a "Plan tasks" child task
- [ ] Dependencies set so features execute in correct order
- [ ] First "Plan tasks" task has no blockers (ready to execute)
- [ ] Feature descriptions include:
  - [ ] Files to create/modify
  - [ ] Testing requirements section with test IDs from spec
  - [ ] E2E scenarios this feature contributes to
  - [ ] Quality gate criteria
  - [ ] Reference documentation

## Step 6: Create Regression Testing Feature

The **final feature** of every phase MUST be a Regression Testing feature. This is the phase-level quality gate.

### Purpose

- Verify all phase functionality works end-to-end
- Catch regressions from prior phases
- Document expected system behavior
- Gate phase completion

### Regression Feature Template

```markdown
# Feature: Phase {N} Regression Testing

## Overview
Execute the full regression test pack to verify Phase {N} functionality
and ensure no regressions from prior work. This is the final quality gate
before the phase is considered complete.

## Regression Pack Location
docs/testing/regression-pack.md

## What This Feature Does
- Executes all regression tests for Phase {N} and prior phases
- Verifies expected outcomes
- Reports PASS/FAIL for each test
- Blocks phase completion until all tests pass

## Testing Requirements
- All tests in regression pack must pass
- Any failures must be fixed before closing

## Reference Documentation
- docs/testing/regression-pack.md - Test scenarios to execute
- docs/testing/phase{N}-test-specification.md - Detailed acceptance criteria
```

### Regression Feature Tasks

The "Plan tasks" for this feature should create a single task:

```markdown
## Objective
Execute all regression tests and verify Phase {N} functionality.

## Instructions
1. Read docs/testing/regression-pack.md
2. Execute each test scenario in "Phase {N} Tests" AND all prior phase sections
3. For each test:
   - Follow the steps exactly
   - Verify expected outcomes
   - Record PASS or FAIL with details
4. If any test fails:
   - Document the failure in detail
   - Do NOT close this task
   - Create a blocking bug task to fix the issue
5. Only close when ALL regression tests pass

## Report Format
For each test, output:
- Test ID: PASS/FAIL
- Details: [what was observed]

## Acceptance Criteria
- [ ] All regression tests executed
- [ ] All tests PASS
- [ ] Results documented
```

### After Phase Completion

After the regression testing feature closes:
1. The phase is complete
2. Add any new regression tests to the pack for the next phase
3. Future phases will run the full cumulative pack

### Dependency

The Regression Testing feature's "Plan tasks" task must be blocked by all other features in the phase:

```bash
# Regression testing waits for all implementation features
bd dep add beads-plan-regression beads-feature-last-impl
```

## Notes

- Do NOT create implementation tasks - that's the job of each "Plan tasks" task
- Do NOT start any implementation work
- Focus on clear feature boundaries and comprehensive descriptions
- The quality of feature descriptions directly impacts agent effectiveness
- Always include Regression Testing as the final feature
